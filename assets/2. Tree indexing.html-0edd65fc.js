import{_ as o,r as a,o as n,c as r,a as e,b as i,d as s,e as h}from"./app-1ed94c4d.js";const l={},d=h('<h1 id="tree-indexing" tabindex="-1"><a class="header-anchor" href="#tree-indexing" aria-hidden="true">#</a> Tree indexing</h1><p>Tree might be the most common traditional indexing that are adopted by human-being before the advent of computers. People have practiced organizing books in nested section for thousands of year.ã€€It has two advantages:</p><ul><li>Tree structure help the reader locate the knowledge, when the reader has already understood parts of the knowledge.</li><li>Tree structure help the readers to understand the relation between different knowledge. Similar knowledge are usually put in the same section or subsection.</li></ul><p>This is the most obvious reason and this is why we call it indexing. However, there are more subtle reasons:</p><ul><li>Tree structure help the readers to understand the context of the knowledge.</li></ul><p>These reasons are important when the reader is not familiar with the knowledge. It makes it possible to understand the knowledge better without reading the whole book. It works by the following mechanism:</p><ul><li>The path from the root section to the current section forms a natural context for the knowledge.</li><li>The readers can choose which section to move to if they find the current section is too trivial, too difficult or too irrelevant to what they want. The tree structure offers a natural path to move.</li></ul><h2 id="what-does-it-mean-to-llm" tabindex="-1"><a class="header-anchor" href="#what-does-it-mean-to-llm" aria-hidden="true">#</a> What does it mean to LLM?</h2><p>The reason why we underscore the importance of tree indexing is obviously not because we want to make a better book. Our question is whether LLM can benefit from tree indexing. The answer is obviously yes. The reason is from the following points:</p><ul><li>We only want LLM to read a book when it does not understand it well. Therefore, it is more similar to the case when the reader is not familiar with the knowledge. This means they need more hint of the context. The path can be a good hint.</li><li>When we want carry out embedding search on the knowledge, it is always more reasonable to include the context. The path can be a good context to make the embedding better.</li></ul><p>Further, if we make the LLM into an agent who can actively travel on the book and add new content to the book.</p><ul><li>The tree structure helps the agent explore related knowledge along the tree and filter out the useful ones. This improves the search result especially when the query is abstract and implicitly related to the knowledge.</li><li>The existing tree structure offers a good reference to create new ones to keep the book organized and easy to read even when the book is very large.</li></ul><h2 id="what-is-the-difference-between-tree-indexing-for-human-and-for-llm" tabindex="-1"><a class="header-anchor" href="#what-is-the-difference-between-tree-indexing-for-human-and-for-llm" aria-hidden="true">#</a> What is the difference between tree indexing for human and for LLM?</h2><p>Usually, in human made books, the tree structure is quite coarse. One of the reasons might be this: explicit fine-grained tree structure is hard to make and read. Though human writers might make a lot of list and aside to make the tree structure actually more fine-grained, it is laborious to give a name to every small section. The human readers are also not willing to read a book with too many small sections.</p><p>However, the situation does not hold for LLM. This is because</p><ul><li>The cost of LLM to write or read is much lower than human. It is not a problem to write a lot of small sections or read them.</li><li>Because LLM does not come with a long-term memory system, it is more important to make the context explicit. The books for human does not assume the readers read each section directly. They can use their long-term memory to make the context. However, LLM does not have such ability.</li></ul><h1 id="wrap-up" tabindex="-1"><a class="header-anchor" href="#wrap-up" aria-hidden="true">#</a> Wrap up</h1><p>With the discussion above, we know that</p><ul><li>Tree indexing is a time-tested way to organize knowledge.</li><li>Tree indexing is important for LLM to understand the knowledge better.</li><li>Tree indexing for LLM can be more fine-grained than that for human.</li></ul><p>As we discussed in the first article, indexing is closed related to understanding. Surely, we can see that tree indexing can help organizing and retrieve knowledge. However, could it really help LLM to understand abstract things like science?</p><h1 id="related-works" tabindex="-1"><a class="header-anchor" href="#related-works" aria-hidden="true">#</a> Related works</h1>',21),c={href:"https://arxiv.org/abs/2310.05029",target:"_blank",rel:"noopener noreferrer"};function u(m,w){const t=a("ExternalLinkIcon");return n(),r("div",null,[d,e("p",null,[e("a",c,[i("Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading"),s(t)])])])}const g=o(l,[["render",u],["__file","2. Tree indexing.html.vue"]]);export{g as default};
