
# TL;DR

- Indexing and understanding have many similarities. They both require adding context to the objective.
- Therefore, we want to implement better understand by AI with super-fine indexing with a rich structure which allows the AI find the context easily and precisely.
- Our plan is from two sides. One for the structure of the knowledge (indexing), one for the retrieval of the knowledge (searching).

# Indexing

- We want to use the tree structure to index the knowledge, because the path from the root to the interested node forms a natural context.
- We want to use LLM (or agent) to generate characterizing strings as the vector indexing of the knowledge, instead of using their embedding directly.
- We want to construct multiple trees in difference levels, with each level corresponding to a different level of abstraction.

# Searching
- We want to use the tree structure to search the knowledge. An agent travelling on the tree will be developed.
- We want to use LLM (or agent) to generate characterizing strings for the queries, instead of using their embedding directly.
- We want to use multiple levels of trees to search the knowledge. The agent should go from the most abstract level to the most concrete level.